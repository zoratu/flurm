#!/bin/bash
#SBATCH --job-name=dep_stage3
#SBATCH --partition=debug
#SBATCH --cpus-per-task=1
#SBATCH --mem=256M
#SBATCH --time=00:01:00
#SBATCH --output=/tmp/dep_stage3_%j.out
#SBATCH --error=/tmp/dep_stage3_%j.err

# NOTE: This job should be submitted with: --dependency=afterok:<stage2_job_id>

echo "=== FLURM Test Job: Dependency Stage 3 (Aggregation) ==="
echo "Job ID: $SLURM_JOB_ID"
echo "Hostname: $(hostname)"
echo "Start time: $(date)"

# Find processed data from stage 2
PROCESSED_FILES=$(ls /tmp/pipeline_processed_*.txt 2>/dev/null | head -1)

if [ -z "$PROCESSED_FILES" ]; then
    echo "WARNING: No processed file found from stage 2"
    echo "Creating placeholder..."
    PROCESSED_FILES="/tmp/pipeline_processed_placeholder.txt"
    echo "item_count=0" > "$PROCESSED_FILES"
    echo "item_sum=0" >> "$PROCESSED_FILES"
fi

echo "Aggregating from: $PROCESSED_FILES"

# Final aggregation
FINAL_FILE="/tmp/pipeline_final_${SLURM_JOB_ID}.txt"

echo "=== Pipeline Final Report ===" > "$FINAL_FILE"
echo "Generated by: $SLURM_JOB_ID" >> "$FINAL_FILE"
echo "Timestamp: $(date)" >> "$FINAL_FILE"
echo "" >> "$FINAL_FILE"

# Copy processed data
cat "$PROCESSED_FILES" >> "$FINAL_FILE"

echo "" >> "$FINAL_FILE"
echo "Pipeline completed successfully!" >> "$FINAL_FILE"

cat "$FINAL_FILE"

echo "End time: $(date)"
echo "SUCCESS - Stage 3 (final) complete"
echo "Final report: $FINAL_FILE"
