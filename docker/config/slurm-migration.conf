# SLURM Configuration for Migration Testing
# Minimal but functional configuration for testing hot migration to FLURM

ClusterName=migration-test
SlurmctldHost=slurm-controller

# Ports
SlurmctldPort=6817
SlurmdPort=6818

# Authentication
AuthType=auth/munge
CryptoType=crypto/munge

# Directories
SlurmdSpoolDir=/var/spool/slurm/d
SlurmctldPidFile=/var/run/slurm/slurmctld.pid
SlurmdPidFile=/var/run/slurm/slurmd.pid
StateSaveLocation=/var/spool/slurm/ctld
SlurmdLogFile=/var/log/slurm/slurmd.log
SlurmctldLogFile=/var/log/slurm/slurmctld.log

# User
SlurmUser=slurm
SlurmdUser=root

# Scheduling
SchedulerType=sched/backfill
SelectType=select/cons_tres
SelectTypeParameters=CR_Core

# Process tracking - use pgid for Docker compatibility (no cgroup deps)
ProctrackType=proctrack/pgid
TaskPlugin=task/none

# Return to service after node recovery
ReturnToService=2

# Switch type
SwitchType=switch/none

# MPI
MpiDefault=none

# Logging
SlurmdDebug=info
SlurmctldDebug=info

# Job handling
CompleteWait=5
KillWait=30
MinJobAge=300
OverTimeLimit=0

# Node definitions
# Compute nodes for migration e2e compose topology
NodeName=compute-node-1 CPUs=1 RealMemory=970 State=UNKNOWN
NodeName=compute-node-2 CPUs=1 RealMemory=970 State=UNKNOWN

# Partition definitions
PartitionName=debug Nodes=compute-node-1,compute-node-2 Default=YES MaxTime=00:30:00 State=UP
PartitionName=batch Nodes=compute-node-1,compute-node-2 MaxTime=24:00:00 State=UP
PartitionName=gpu Nodes=compute-node-1,compute-node-2 MaxTime=48:00:00 State=UP
